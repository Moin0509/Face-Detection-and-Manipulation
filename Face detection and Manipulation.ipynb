{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13ef066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fc789",
   "metadata": {},
   "source": [
    "### Face detection using haarcascade classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    \n",
    "    try:\n",
    "        face=classifier.detectMultiScale(img,1.1,4)\n",
    "        for(x,y,w,z) in face:\n",
    "            cv.rectangle(img,(x,y),(x+w,y+z),(0,0,128),3)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv.imshow(\"Frame\",img)\n",
    "    \n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a011d16",
   "metadata": {},
   "source": [
    "### Cropping face into another window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8683f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    \n",
    "    face=classifier.detectMultiScale(img,1.1,4)\n",
    "    \n",
    "    for f in face:\n",
    "        if f[-1]==max(face[:,-1]):\n",
    "            break\n",
    "    if (len(face)>=1):\n",
    "        x=f[0]\n",
    "        y=f[1]\n",
    "        w=f[2]\n",
    "        z=f[3]\n",
    "        \n",
    "        cv.rectangle(img,(x,y),(x+w,y+z),(0,0,128),3)\n",
    "        crop=img[y:y+z,x:x+w]\n",
    "       #crop=cv.resize(crop,(256,256))-- doesn't change the window size and keeps it fixed\n",
    "        \n",
    "    cv.imshow(\"Frame\",img)\n",
    "    cv.imshow(\"Cropped\",crop)\n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee88c4e",
   "metadata": {},
   "source": [
    "### Blurring face from cropped video in main frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    \n",
    "    face=classifier.detectMultiScale(img,1.1,4)\n",
    "    \n",
    "    for f in face:\n",
    "        if f[-1]==max(face[:,-1]):\n",
    "            break\n",
    "    if (len(face)>=1):\n",
    "        x=f[0]\n",
    "        y=f[1]\n",
    "        w=f[2]\n",
    "        z=f[3]\n",
    "        \n",
    "        \n",
    "        crop=img[y-50:y+z+50,x:x+w]\n",
    "       #crop=cv.resize(crop,(256,256))-- doesn't change the window size and keeps it fixed\n",
    "        crop=cv.blur(crop,(8,8))\n",
    "        img[y-50:y+z+50,x:x+w]=crop\n",
    "    cv.imshow(\"Frame\",img)\n",
    "    cv.imshow(\"Cropped\",crop)\n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411b5be",
   "metadata": {},
   "source": [
    "### Blurring background of main frame using cropped frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    \n",
    "    face=classifier.detectMultiScale(img,1.1,4)\n",
    "    \n",
    "    for f in face:\n",
    "        if f[-1]==max(face[:,-1]):\n",
    "            break\n",
    "    if (len(face)>=1):\n",
    "        x=f[0]\n",
    "        y=f[1]\n",
    "        w=f[2]\n",
    "        z=f[3]\n",
    "        \n",
    "        \n",
    "        crop=img[y-30:y+z+30,x:x+w]\n",
    "       #crop=cv.resize(crop,(256,256))-- doesn't change the window size and keeps it fixed\n",
    "        img=cv.blur(img,(32,32))\n",
    "        img[y-30:y+z+30,x:x+w]=crop\n",
    "    cv.imshow(\"Frame\",img)\n",
    "    cv.imshow(\"Cropped\",crop)\n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f48d73",
   "metadata": {},
   "source": [
    "### Making a circle instead of square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95987f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    face=classifier.detectMultiScale(img,1.1,4)\n",
    "    \n",
    "    for f in face:\n",
    "        if f[-1]==max(face[:,-1]):\n",
    "            break\n",
    "\n",
    "    x=f[0]\n",
    "    y=f[1]\n",
    "    w=f[2]\n",
    "    z=f[3]\n",
    "       \n",
    "    circle_x=x+int(w/2)\n",
    "    circle_y=y+int(z/2)\n",
    "    cv.circle(img,(circle_x,circle_y),150,(0,0,255),2)\n",
    "    \n",
    "    cv.imshow(\"Frame\",img)\n",
    "\n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd6ce9",
   "metadata": {},
   "source": [
    "### Filling colour inside circle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    face=classifier.detectMultiScale(img,1.1,4)\n",
    "    \n",
    "    for f in face:\n",
    "        if f[-1]==max(face[:,-1]):\n",
    "            break\n",
    "\n",
    "    x=f[0]\n",
    "    y=f[1]\n",
    "    w=f[2]\n",
    "    z=f[3]\n",
    "       \n",
    "    circle_x=x+int(w/2)\n",
    "    circle_y=y+int(z/2)\n",
    "    cv.circle(img,(circle_x,circle_y),150,(0,0,255),-1)\n",
    "    \n",
    "    cv.imshow(\"Frame\",img)\n",
    "\n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b3e1b",
   "metadata": {},
   "source": [
    "### Making the circle dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7540cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam=cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img=cam.read()\n",
    "    img=cv.flip(img,1)\n",
    "    face=classifier.detectMultiScale(img,1.1,4)\n",
    "    \n",
    "    for f in face:\n",
    "        if f[-1]==max(face[:,-1]):\n",
    "            break\n",
    "\n",
    "    x=f[0]\n",
    "    y=f[1]\n",
    "    w=f[2]\n",
    "    z=f[3]\n",
    "       \n",
    "    circle_x=x+int(w/2)\n",
    "    circle_y=y+int(z/2)\n",
    "    cv.circle(img,(circle_x,circle_y),int(w/1.6),(0,0,255),2)\n",
    "    \n",
    "    cv.imshow(\"Frame\",img)\n",
    "\n",
    "    if(cv.waitKey(1))==27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08a441",
   "metadata": {},
   "source": [
    "### Detecting Faces in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2ff3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "img=cv.imread('1.jpg')\n",
    "face=classifier.detectMultiScale(img,1.2,4)\n",
    "    \n",
    "for (x,y,w,z) in face:\n",
    "    cv.rectangle(img,(x,y),(x+w,y+z),(0,0,128),2)\n",
    "\n",
    "cv.imwrite(\"Transformed.jpg\",img)  #export the image\n",
    "cv.imshow(\"Frame\",img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2c24f",
   "metadata": {},
   "source": [
    "### Exporting face from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05adec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted/IMG_4.jpg is exported\n",
      "Extracted/IMG_5.jpg is exported\n",
      "Extracted/IMG_6.jpg is exported\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('1.jpg')\n",
    "\n",
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = classifier.detectMultiScale(img, 1.1, 4)\n",
    "\n",
    "\n",
    "def save(frame, folder_name): \n",
    "    name_img = len(os.listdir(folder_name)) + 1\n",
    "    name_img = folder_name + \"/IMG_\" + str(name_img) + '.jpg'\n",
    "    cv.imwrite(name_img, frame)\n",
    "    print(name_img ,'is exported')\n",
    "\n",
    "\n",
    "for (x,y,w,z) in faces:\n",
    "\n",
    "    face = img[y:y+z, x:x+w]\n",
    "    cv.imshow('Face'   , face)\n",
    "    \n",
    "    \n",
    "    if cv.waitKey(0) == 13:         # Save the Image | 13  = Enter Key\n",
    "        save(face, 'Extracted')\n",
    "    \n",
    "    elif cv.waitKey(0) == 127:      # Skip the Image | 127 = Delete Key\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2eda79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
